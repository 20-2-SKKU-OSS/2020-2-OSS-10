{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaRVrGm7vTPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from torch.utils import data as D\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "\n",
        "transformer = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                 ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2wlrRJavZIa",
        "colab_type": "code",
        "outputId": "64f6226a-8c35-483d-8a94-27f9ee049408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transformer)\n",
        "\n",
        "validset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transformer)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transformer)\n",
        "\n",
        "num_train = len(trainset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(0.1 * num_train))\n",
        "\n",
        "np.random.seed(10)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=100, sampler=train_sampler)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(dataset=validset, batch_size=100, sampler=valid_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=100, shuffle=False)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUmR_23XvjGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "   \n",
        "    self.fc1 = nn.Linear(3072, 768)\n",
        "    self.fc2 = nn.Linear(768, 384)\n",
        "    self.fc3=nn.Linear(384,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "   \n",
        "    x = x.view(-1, 3072)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  \n",
        "model = LeNet()\n",
        "device=torch.device(\n",
        "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IRAV3S6wEHO",
        "colab_type": "code",
        "outputId": "5685fe35-b87c-4f0a-dcfd-bc65ffe07c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "running_loss_history = []\n",
        "running_correct_history = []\n",
        "validation_running_loss_history = [] \n",
        "validation_running_correct_history = []\n",
        "\n",
        "for e in range(epochs):  \n",
        "    \n",
        "    running_loss = 0.0\n",
        "    running_correct = 0.0\n",
        "    validation_running_loss = 0.0\n",
        "    validation_running_correct = 0.0\n",
        "\n",
        "    # training part  \n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "    \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        _, preds = torch.max(outputs, 1)   \n",
        "        running_correct += torch.sum(preds == labels.data)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = running_correct.float() / len(train_loader)\n",
        "        running_loss_history.append(epoch_loss)\n",
        "        running_correct_history.append(epoch_acc)\n",
        "\n",
        "              \n",
        "  # validation part\n",
        "   \n",
        "    for i, data in valid_loader:\n",
        "        val_inputs = i.to(device)\n",
        "        val_labels = data.to(device)\n",
        "        val_outputs = model(val_inputs)\n",
        "        val_loss = criterion(outputs, labels)\n",
        "\n",
        "        _, val_preds = torch.max(val_outputs, 1)\n",
        "        validation_running_loss += val_loss.item()\n",
        "        validation_running_correct += torch.sum(val_preds == val_labels.data)\n",
        "\n",
        "        val_epoch_loss = validation_running_loss / len(valid_loader)\n",
        "        val_epoch_acc = validation_running_correct.float() / len(valid_loader)\n",
        "        validation_running_loss_history.append(val_epoch_loss)\n",
        "        validation_running_correct_history.append(val_epoch_acc) \n",
        "\n",
        "    print(\"epoch: \", e + 1)\n",
        "    print(\"training loss: {:.5f}, acc: {:5f}\".format(epoch_loss, epoch_acc))\n",
        "    print(\"validation loss: {:.5f}, acc: {:5f}\".format(val_epoch_loss, val_epoch_acc))\n",
        "        "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1\n",
            "training loss: 1.64791, acc: 41.459999\n",
            "validation loss: 1.44578, acc: 46.320000\n",
            "epoch:  2\n",
            "training loss: 1.43183, acc: 49.255554\n",
            "validation loss: 1.23155, acc: 49.480000\n",
            "epoch:  3\n",
            "training loss: 1.31455, acc: 53.515556\n",
            "validation loss: 1.38003, acc: 52.180000\n",
            "epoch:  4\n",
            "training loss: 1.21027, acc: 57.168888\n",
            "validation loss: 1.16927, acc: 51.720001\n",
            "epoch:  5\n",
            "training loss: 1.12245, acc: 60.046665\n",
            "validation loss: 1.24256, acc: 53.160000\n",
            "epoch:  6\n",
            "training loss: 1.03499, acc: 63.062222\n",
            "validation loss: 1.06653, acc: 52.459999\n",
            "epoch:  7\n",
            "training loss: 0.94680, acc: 66.473335\n",
            "validation loss: 0.87105, acc: 52.419998\n",
            "epoch:  8\n",
            "training loss: 0.86172, acc: 69.428886\n",
            "validation loss: 0.66146, acc: 53.040001\n",
            "epoch:  9\n",
            "training loss: 0.78718, acc: 71.986664\n",
            "validation loss: 0.84031, acc: 54.720001\n",
            "epoch:  10\n",
            "training loss: 0.70198, acc: 75.033333\n",
            "validation loss: 0.81719, acc: 53.560001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3B0GMCBwGBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c197bb4f-97e8-4c4b-b99b-f53c194060cf"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# test part\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "                \n",
        "        for i in range(labels.shape[0]):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the test images: %d %%' % (100 * correct / total))            "
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the test images: 53 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}